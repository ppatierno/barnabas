// This assembly is included in the following assemblies:
//
// master.adoc

// Save the context of the assembly that is including this one.
// This is necessary for including assemblies in assemblies.
// See also the complementary step on the last line of this file.
:parent-context: {context}

include::common/attributes.adoc[]

[id='getting-started-{context}']
= Getting started

{ProductName} runs on
ifdef::Kubernetes[{KubernetesLongName} {KubernetesVersion} and]
{OpenShiftLongName} {OpenShiftVersion}.

{ProductName} works on all kinds of clusters - from public and private clouds down to local deployments intended for development.
This guide expects that an {ProductPlatformName} cluster is available and the
ifdef::Kubernetes[`kubectl` and]
`oc` command-line tools are installed and configured to connect to the running cluster.

ifdef::InstallationAppendix[]
When no existing {ProductPlatformName} cluster is available, `Minikube` or `Minishift` can be used to create a local
cluster. More details can be found in xref:installing_kubernetes_and_openshift_cluster[Installing Kubernetes and OpenShift clusters].
endif::InstallationAppendix[]

[NOTE]
To run the commands in this guide, your
ifdef::Kubernetes[{KubernetesLongName} and]
{OpenShiftLongName} user must have the rights to manage role-based access control (RBAC).

ifdef::Downloading[]
include::con-product-downloads.adoc[leveloffset=+1]
endif::Downloading[]

include::assembly-cluster-operator.adoc[leveloffset=+1]

include::assembly-kafka-cluster.adoc[leveloffset=+1]

include::assembly-kafka-connect.adoc[leveloffset=+1]

//Modularized above here

== Topic Operator

{ProductName} uses a component called the Topic Operator to manage topics in the Kafka cluster.
The Topic Operator is deployed as a process running inside a {ProductPlatformName} cluster.
To create a new Kafka topic, a `KafkaTopic` custom resource with the related configuration (name, partitions, replication factor, ...) has to be created.
Based on the information in that `KafkaTopic`, the Topic Operator will create a corresponding Kafka topic in the cluster.

Deleting a `KafkaTopic` causes the deletion of the corresponding Kafka topic as well.

The Cluster Operator is able to deploy a Topic Operator, which can be configured in the `Kafka` resource.
Alternatively, it is possible to deploy a Topic Operator manually, rather than having it deployed by the Cluster Operator.


include::proc-deploying-the-topic-operator-using-the-cluster-operator.adoc[leveloffset=+2]

=== Deploying standalone Topic Operator

If you are not going to deploy the Kafka cluster using the Cluster Operator but you already have a Kafka cluster deployed
on {ProductPlatformName}, it could be useful to deploy the Topic Operator using the provided YAML files.
In that case you can still leverage on the Topic Operator features of managing Kafka topics through related `KafkaTopics`.

ifdef::Kubernetes[]
==== Deploying to {KubernetesName}

To deploy the Topic Operator on {KubernetesName} (not through the Cluster Operator), the following command should be executed:

[source,shell]
kubectl create -f examples/install/topic-operator.yaml

To verify whether the Topic Operator has been deployed successfully, the {KubernetesName} Dashboard or the following
command can be used:

[source,shell]
kubectl describe all
endif::Kubernetes[]

==== Deploying to {OpenShiftName}

To deploy the Topic Operator on {OpenShiftName} (not through the Cluster Operator), the following command should be executed:

[source,shell]
oc create -f examples/install/topic-operator

To verify whether the Topic Operator has been deployed successfully, the {OpenShiftName} console or the following command
can be used:

[source,shell]
oc describe all

==== `KafkaTopic` resources

When the Topic Operator is deployed by the Cluster Operator it will be configured to watch for `KafkaTopics` with the label `strimzi.io/cluster: _<cluster-name>_`

NOTE: When the Topic Operator is deployed manually the `strimzi.io/cluster` label is not necessary.

The `KafkaTopic` contains the topic configuration in a specific format, described in xref:format-of-the-kafkatopic-{context}[Format of the `KafkaTopic`].

=== Logging
The `logging` field allows the configuration of loggers. These loggers are listed below.
[source]
rootLogger.level

For information on the logging options and examples of how to set logging, see <<logging_examples, logging examples>> for Kafka.

When using external ConfigMap remember to place your custom ConfigMap under `log4j2.properties` key.

// Restore the context to what it was before this assembly.
:context: {parent-context}
