[id='kafka-config-map-details_{context}']
= Kafka resource configurations

The table below lists the fields that you can use when configuring a Kafka cluster deployment. A dot is used to denote a nexted YAML object.

.Kafka Cluster Deployment Configuration Elements
[cols="30%,50%,20%",options="header"]
|===
|Element
|Description
|Default Value

|`spec.kafka.replicas`
|The number of Kafka broker nodes.
|3

|`spec.kafka.image`
|The Docker image to be used by the Kafka brokers.The default value is determined by the value specified in the xref:STRIMZI_DEFAULT_KAFKA_IMAGE[`STRIMZI_DEFAULT_KAFKA_IMAGE`] environment variable of the Cluster Operator.
|

|`spec.kafka.brokerRackInitImage`
| The Docker image to be used by the init container which does some initial configuration work (that is, rack support). The default value is determined by the value specified in the xref:STRIMZI_DEFAULT_KAFKA_INIT_IMAGE[`STRIMZI_DEFAULT_KAFKA_INIT_IMAGE`] environment variable of the Cluster Operator.
|

|`spec.kafka.livenessProbe.initialDelaySeconds`
|The initial delay for the liveness probe for each Kafka broker node.
|15

|`spec.kafka.livenessProbe.timeoutSeconds`
|The timeout on the liveness probe for each Kafka broker node.
|5

|`spec.kafka.readinessProbe.initialDelaySeconds`
|The initial delay for the readiness probe for each Kafka broker node.
|15

|`spec.kafka.readinessProbe.timeoutSeconds`
|The timeout on the readiness probe for each Kafka broker node.
|5

|`spec.kafka.config`
|The Kafka broker configuration. For more information, see xref:kafka_configuration_json_config[Kafka Configuration] for more details.
|

|`spec.kafka.storage`
|The storage configuration for the Kafka broker nodes. For more information, see xref:kafka_configuration_json_config[Kafka Configuration] for more details.
|
|===


`spec.kafka.metrics`::
The JMX exporter configuration for exposing metrics from Kafka broker nodes.
When this field is absent no metrics will be exposed.

[id=spec.kafka.logging-{context}]`spec.kafka.logging`::
An object that specifies inline logging levels or the name of external config map that specifies the logging levels.
When this field is absent default values are used.
List of loggers which can be set:
[source]
kafka.root.logger.level
log4j.logger.org.I0Itec.zkclient.ZkClient
log4j.logger.org.apache.zookeeper
log4j.logger.kafka
log4j.logger.org.apache.kafka
log4j.logger.kafka.request.logger
log4j.logger.kafka.network.Processor
log4j.logger.kafka.server.KafkaApis
log4j.logger.kafka.network.RequestChannel$
log4j.logger.kafka.controller
log4j.logger.kafka.log.LogCleaner
log4j.logger.state.change.logger
log4j.logger.kafka.authorizer.logger

`spec.kafka.resources`::
The resource limits and requests for Kafka broker containers.
The accepted format is described in the xref:resources_json_config[Resource limits and requests] section.
`spec.kafka.jvmOptions`::
An object allowing the JVM running Kafka to be configured.
The accepted format is described in the xref:jvm_json_config[JVM Options] section.
`spec.kafka.rack`::
An object allowing the Kafka rack feature to be configured and used in rack-aware partition assignment for fault tolerance.
For information about the accepted JSON format, see xref"kafka_rack[Kafka Rack] section.
`spec.kafka.affinity`::
An object allowing control over how the Kafka pods are scheduled to nodes.
The format of the corresponding key is the same as the content supported in the Pod `affinity` in {ProductPlatformName}.
For more information, see xref:affinity[Node and Pod Affinity].
`spec.kafka.tlsSidecar.image`::
The Docker image to be used by the sidecar container which provides TLS support for Kafka brokers.
The default value is determined by the value specified in the xref:STRIMZI_DEFAULT_TLS_SIDECAR_KAFKA_IMAGE[`STRIMZI_DEFAULT_TLS_SIDECAR_KAFKA_IMAGE`] environment variable of the Cluster Operator.
`spec.kafka.tlsSidecar.resources`::
An object configuring the resource limits and requests for the sidecar container which provides TLS support for Kafka brokers.
For information about the accepted JSON format, see xref:resources_json_config[Resource limits and requests].
`spec.zookeeper.replicas`::
The number of Zookeeper nodes.
`spec.zookeeper.image`::
The Docker image to be used by the Zookeeper nodes.
The default value is determined by the value specified in the xref:STRIMZI_DEFAULT_ZOOKEEPER_IMAGE[`STRIMZI_DEFAULT_ZOOKEEPER_IMAGE]` environment variable of the Cluster Operator.
`spec.zookeeper.livenessProbe.initialDelaySeconds`::
The initial delay for the liveness probe for each Zookeeper node.
Default is 15.
`spec.zookeeper.livenessProbe.initialDelaySeconds`::
The timeout on the liveness probe for each Zookeeper node.
Default is 5.
`spec.zookeeper.readinessProbe.initialDelaySeconds`::
The initial delay for the readiness probe for each Zookeeper node.
Default is 15.
`spec.zookeeper.readinessProbe.initialDelaySeconds`::
The timeout on the readiness probe for each Zookeeper node.
Default is 5.
`spec.zookeeper.config`::
The Zookeeper configuration. For more information, see xref:zookeeper_configuration_json_config[Zookeeper Configuration].
`spec.zookeeper.storage`::
The storage configuration for the Zookeeper nodes. For more information, see xref:storage_configuration_json_config[Storage].
`spec.zookeeper.metrics`::
The JMX exporter configuration for exposing metrics from Zookeeper nodes.
When this field is absent no metrics will be exposed.
[[spec.zookeeper.logging]]`spec.zookeeper.logging`::
An object that specifies inline logging levels or the name of external config map that specifies the logging levels.
When this field is absent default values are used.
List of loggers which can be set:
[source]
zookeeper.root.logger

`spec.zookeeper.resources`::
An object configuring the resource limits and requests for Zookeeper broker containers.
For information about the accepted JSON format, see xref:resources_json_config[Resource limits and requests].
`spec.zookeeper.jvmOptions`::
An object allowing the JVM running Zookeeper to be configured.
For information about the accepted JSON format, see xref:jvm_json_config[JVM Options] section.
`spec.zookeeper.affinity`::
An object allowing control over how the Zookeeper pods are scheduled to nodes.
The format of the corresponding key is the same as the content supported in the Pod `affinity` in {ProductPlatformName}.
For more information, see xref:affinity[Node and Pod Affinity].
`spec.zookeeper.tlsSidecar.image`::
The Docker image to be used by the sidecar container which provides TLS support for Zookeeper nodes.
The default value is determined by the value specified in the xref:STRIMZI_DEFAULT_TLS_SIDECAR_ZOOKEEPER_IMAGE[`STRIMZI_DEFAULT_TLS_SIDECAR_ZOOKEEPER_IMAGE`] environment variable of the Cluster Operator.
`spec.zookeeper.tlsSidecar.resources`::
An object configuring the resource limits and requests for the sidecar container which provides TLS support for Zookeeper nodes.
For information about the accepted JSON format, see xref:resources_json_config[Resource limits and requests].
`spec.topicOperator`::
An object representing the topic operator configuration. For more information, see xref:topic_operator_json_config[Topic Operator].


More info about the topic operator in the related xref:topic-operator-{context}[Topic Operator] documentation page.

The following is an example of a Kafka resource.

.Example `Kafka` resource
[source,yaml,options="nowrap",subs="attributes"]
----
apiVersion: {KafkaApiVersion}
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    replicas: 3
    image: "{DockerKafka}"
    kafka-healthcheck-delay: "15"
    kafka-healthcheck-timeout: "5"
    config:
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
    storage:
      type: ephemeral
    metrics:
      {
        "lowercaseOutputName": true,
        "rules": [
            {
              "pattern": "kafka.server&lt;type=(.+), name=(.+)PerSec\\w*&gt;&lt;&gt;Count",
              "name": "kafka_server_$1_$2_total"
            },
            {
              "pattern": "kafka.server&lt;type=(.+), name=(.+)PerSec\\w*, topic=(.+)&gt;&lt;&gt;Count",
              "name": "kafka_server_$1_$2_total",
              "labels":
              {
                "topic": "$3"
              }
            }
        ]
      }
    logging:
      type: external
      name: customConfigMap
  zookeeper:
    replicas: 1
    image: {DockerZookeeper}
    healthcheck-delay: "15"
    healthcheck-timeout: "5"
    config:
      timeTick: 2000,
      initLimit: 5,
      syncLimit: 2,
      autopurge.purgeInterval: 1
    storage:
      type: ephemeral
    metrics:
      {
        "lowercaseOutputName": true
      }
    logging:
      type : inline
      loggers :
        zookeeper.root.logger: INFO
----

The resources created by the Cluster Operator in the {ProductPlatformName} cluster will be the following :

`[cluster-name]-zookeeper`:: StatefulSet which is in charge of managing the Zookeeper node pods
`[cluster-name]-kafka`:: StatefulSet which is in charge of managing the Kafka broker pods
`[cluster-name]-zookeeper-nodes`:: Service needed to have DNS resolve the Zookeeper pods IP addresses directly
`[cluster-name]-kafka-brokers`:: Service needed to have DNS resolve the Kafka broker pods IP addresses directly
`[cluster-name]-zookeeper-client`:: Service used by Kafka brokers to connect to Zookeeper nodes as clients
`[cluster-name]-kafka-bootstrap`:: Service can be used as bootstrap servers for Kafka clients
`[cluster-name]-zookeeper-metrics-config`:: ConfigMap which contains the Zookeeper metrics configuration and mounted as a volume by the Zookeeper node pods
`[cluster-name]-kafka-metrics-config`:: ConfigMap which contains the Kafka metrics configuration and mounted as a volume by the Kafka broker pods
`[cluster-name]-zookeeper-config`::
ConfigMap which contains the Zookeeper ancillary configuration and is mounted as a volume by the Zookeeper node pods
`[cluster-name]-kafka-config`::
ConfigMap which contains the Kafka ancillary configuration and is mounted as a volume by the Kafka broker pods

[[kafka_configuration_json_config]]
== Kafka Configuration

The `spec.kafka.config` object allows detailed configuration of Apache Kafka. This field should contain a JSON object with Kafka
configuration options as keys. The values could be in one of the following JSON types:

* String
* Number
* Boolean

The `spec.kafka.config` object supports all Kafka configuration options with the exception of options related to:

* Security (Encryption, Authentication and Authorization)
* Listener configuration
* Broker ID configuration
* Configuration of log data directories
* Inter-broker communication
* Zookeeper connectivity

Specifically, all configuration options with keys starting with one of the following strings will be ignored:

* `listeners`
* `advertised.`
* `broker.`
* `listener.`
* `host.name`
* `port`
* `inter.broker.listener.name`
* `sasl.`
* `ssl.`
* `security.`
* `password.`
* `principal.builder.class`
* `log.dir`
* `zookeeper.connect`
* `zookeeper.set.acl`
* `authorizer.`
* `super.user`

All other options will be passed to Kafka.
A list of all the available options can be found on the link:http://kafka.apache.org/11/documentation.html#brokerconfigs[Kafka website^].
An example `spec.kafka.config` field is provided below.

.Example fragment of a `Kafka` resource specifying Kafka configuration
[source,json]
----
apiVersion: {KafkaApiVersion}
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    config:
      num.partitions: 1,
      num.recovery.threads.per.data.dir: 1,
      default.replication.factor: 3,
      offsets.topic.replication.factor: 3,
      transaction.state.log.replication.factor: 3,
      transaction.state.log.min.isr: 1,
      log.retention.hours: 168,
      log.segment.bytes: 1073741824,
      log.retention.check.interval.ms: 300000,
      num.network.threads: 3,
      num.io.threads: 8,
      socket.send.buffer.bytes: 102400,
      socket.receive.buffer.bytes: 102400,
      socket.request.max.bytes: 104857600,
      group.initial.rebalance.delay.ms: 0
    # ...
----

NOTE:: The Cluster Operator does not validate keys or values in the provided `config` object.
When invalid configuration is provided, the Kafka cluster might not start or might become unstable.
In such cases, the configuration in the `spec.kafka.config` object should be fixed and the cluster operator will roll out the new configuration to all Kafka brokers.

[[zookeeper_configuration_json_config]]
== Zookeeper Configuration

The `spec.zookeeper.config` object allows detailed configuration of Apache Zookeeper. This field should contain a JSON object
with Zookeeper configuration options as keys. The values could be in one of the following JSON types:

* String
* Number
* Boolean

The `spec.zookeeper.config` object supports all Zookeeper configuration options with the exception of options related to:

* Security (Encryption, Authentication and Authorization)
* Listener configuration
* Configuration of data directories
* Zookeeper cluster composition

Specifically, all configuration options with keys starting with one of the following strings will be ignored:

* `server.`
* `dataDir`
* `dataLogDir`
* `clientPort`
* `authProvider`
* `quorum.auth`
* `requireClientAuthScheme`

All other options will be passed to Zookeeper.
A list of all the available options can be found on the link:http://zookeeper.apache.org/doc/r3.4.12/zookeeperAdmin.html[Zookeeper website^].
An example `spec.zookeeper.config` object is provided below.

.Example fragment of a `Kafka` resource specifying Zookeeper configuration
[source,json]
----
apiVersion: {KafkaApiVersion}
kind: Kafka
metadata:
  name: my-cluster
spec:
  zookeeper:
    # ...
    config:
      timeTick: 2000,
      initLimit: 5,
      syncLimit: 2,
      quorumListenOnAllIPs: true,
      maxClientCnxns: 0,
      autopurge.snapRetainCount: 3,
      autopurge.purgeInterval: 1
    # ...
----

Selected options have default values:

* `timeTick` with default value `2000`
* `initLimit` with default value `5`
* `syncLimit` with default value `2`
* `autopurge.purgeInterval` with default value `1`

These options will be automatically configured in case they are not present in the `spec.zookeeper.config` object.

NOTE:: The Cluster Operator does not validate keys or values in the provided `config` object.
When invalid configuration is provided, the Zookeeper cluster might not start or might become unstable.
In such cases, the configuration in the `spec.zookeeper.config` object should be fixed and the cluster operator will roll out the new configuration to all Zookeeper nodes.

[[storage_configuration_json_config]]
== Storage

Both Kafka and Zookeeper save data to files.

{ProductName} allows to save such data in an "ephemeral" way (using `emptyDir`) or in a "persistent-claim" way using persistent volumes.
It is possible to provide the storage configuration in the `spec.kafka.storage` and `spec.zookeeper.storage` objects.

IMPORTANT: The `spec.kafka.storage` and `spec.zookeeper.storage` objects cannot be changed when the cluster is up.

The storage object has a mandatory `type` field for specifying the type of storage to use which must be either "ephemeral" or "persistent-claim".

The _ephemeral_ storage is really simple to configure.

.Example fragment of a `Kafka` resource using `ephemeral` storage for Kafka pods
[source,json]
----
apiVersion: {KafkaApiVersion}
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    storage:
      type: ephemeral
    # ...
----

WARNING: If the Zookeeper cluster is deployed using _ephemeral_ storage, the Kafka brokers can have problems dealing with Zookeeper node restarts which could happen via updates in the Kafka resource.

In case of _persistent-claim_ type the following fields can be provided as well:

`size` (required)::
defines the size of the persistent volume claim, for example, _1Gi_.

`class` (optional)::
the {ProductPlatformName} link:https://kubernetes.io/docs/concepts/storage/storage-classes/[storage class^] to use for dynamic volume allocation.

`selector` (optional)::
allows to select a specific persistent volume to use.
It contains a `matchLabels` field which contains key:value pairs representing labels for selecting such a volume.

`delete-claim` (optional)::
boolean value which specifies if the persistent volume claim has to be deleted when the cluster is undeployed.
Default is `false`.

.Example fragment of a `Kafka` resource configuring Kafka with `persistent-storage` and 1Gi `size`
[source,json]
----
apiVersion: {KafkaApiVersion}
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    storage:
      type: persistent-claim
      size: 1Gi
    # ...
----

The following example demonstrates use of a storage class.

.Example fragment of a `Kafka` resource configuring Kafka with `persistent-storage` using a storage class
[source,json]
----
apiVersion: {KafkaApiVersion}
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    storage:
      type: persistent-claim
      size: 1Gi
      class: my-storage-class
    # ...
----

Finally, a `selector` can be used in order to select a specific labelled persistent volume which provides some needed features (such as an SSD)

.Example fragment of a `Kafka` resource configuring Kafka with _match labels_ selector
[source,json]
----
apiVersion: {KafkaApiVersion}
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    storage:
      type: persistent-claim
      size: 1Gi
      selector:
        matchLabels:
          "hdd-type": "ssd"
      deleteClaim: true
    # ...
----

When the "persistent-claim" is used, other than the resources already described in the xref:kafka-config-map-details_{context}[Kafka] section, the following resources are generated :

`data-[cluster-name]-kafka-[idx]`::
Persistent Volume Claim for the volume used for storing data for the Kafka broker pod `[idx]`.

`data-[cluster-name]-zookeeper-[idx]`::
Persistent Volume Claim for the volume used for storing data for the Zookeeper node pod `[idx]`.

See xref:type-EphemeralStorage[`EphemeralStorage` type v1alpha1 kafka.strimzi.io] and xref:type-PersistentClaimStorage[`PersistentClaimStorage` type v1alpha1 kafka.strimzi.io] for further details.

== Metrics

{ProductName} uses the link:https://github.com/prometheus/jmx_exporter[Prometheus JMX exporter^] in order to expose metrics on each node.
It is possible to configure a `metrics` object in the `kafka` and `zookeeper` objects in `Kafka` resources, and likewise a `metrics` object in the `spec` of `KafkaConnect` resources.
In all cases the `metrics` object should be the configuration for the JMX exporter.
You can find more information on how to use it in the corresponding GitHub repo.

For more information about using the metrics with Prometheus and Grafana, see xref:metrics[Metrics]


[id=logging-examples-{context}]
== Logging
The `logging` field allows the configuration of loggers. These loggers for Zookeeper and Kafka are available in the xref:spec.zookeeper.logging[`spec.zookeeper.logging` and xref:spec.kafka.logging-{context}[`spec.kafka.logging`] sections respectively.

The setting can be done in one of two ways. Either by specifying the loggers and their levels directly or by using a custom config map.
An example would look like this:

[source,yaml]
----
  logging:
    type: inline
    loggers:
      logger.name: "INFO"
----
The `INFO` can be replaced with any log4j logger level. The available logger levels are `INFO`, `ERROR`, `WARN`, `TRACE`, `DEBUG`, `FATAL` or `OFF`.
The informations about log levels can be found in the link:https://logging.apache.org/log4j/2.x/manual/customloglevels.html[log4j manual^].

[source,yaml]
----
  logging:
    type: external
    name: customConfigMap
----

When using external ConfigMap remember to place your custom ConfigMap under `log4j.properties` key.

The difference between these two options is that the latter is not validated and does not support default values.
That means the user can supply any logging configuration, even if it is incorrect.
The first option supports default values.


[[resources_json_config]]
== Resource limits and requests

It is possible to configure {ProductPlatformName} resource limits and requests on for the `kafka`, `zookeeper` and `topicOperator` objects in the `Kafka` resource and for for the `spec` object of the `KafkaConnect resource.
The object may have a `requests` and a `limits` property, each having the same schema, consisting of `cpu` and `memory` properties.
The {ProductPlatformName} syntax is used for the values of `cpu` and `memory`.

.Example fragment of a `Kafka` resource configuring resource limits and requests for the Kafka pods
[source,json]
----
apiVersion: {KafkaApiVersion}
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    resources:
      requests:
        cpu: "1"
        memory: "2Gi"
      limits:
        cpu: "1"
        memory: "2Gi"
    # ...
----

:k8s-docs-version: v1-7
:k8s-resource-request-limit-docs-link: https://{k8s-docs-version}.docs.kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/

`requests.memory`::
the memory request for the container, corresponding directly to {k8s-resource-request-limit-docs-link}[`spec.containers[\].resources.requests.memory`] setting.
{ProductPlatformName} will ensure the containers have at least this much memory by running the pod on a node with at
least as much free memory as all the containers require. Optional with no default.
`requests.cpu`::
the cpu request for the container, corresponding directly to {k8s-resource-request-limit-docs-link}[`spec.containers[\].resources.requests.cpu`] setting.
{ProductPlatformName} will ensure the containers have at least this much CPU by running the pod on a node with at least
as much uncommitted CPU as all the containers require. Optional with no default.
`limits.memory`::
the memory limit for the container, corresponding directly to {k8s-resource-request-limit-docs-link}[`spec.containers[\].resources.limits.memory`] setting.
{ProductPlatformName} will limit the containers to this much memory, potentially terminating their pod if they use more.
Optional with no default.
`limits.cpu`::
the cpu limit for the container, corresponding directly to {k8s-resource-request-limit-docs-link}[`spec.containers[\].resources.limits.cpu`] setting.
{ProductPlatformName} will cap the containers CPU usage to this limit. Optional with no default.

More details about resource limits and requests can be found on {k8s-resource-request-limit-docs-link}[{KubernetesName} website].

== Minimum Resource Requirements

Testing has shown that the Cluster Operator functions adequately with 256Mi of memory and 200m CPU when watching two clusters.
It is therefore recommended to use these as a minimum when configuring resource requests and not to run it with lower limits than these.
Configuring more generous limits is recommended, especially when it is controlling multiple clusters.


[id=jvm-json-config-{context}]
== JVM Options

It is possible to configure a subset of available JVM options on Kafka, Zookeeper and Kafka Connect containers.
The object has a property for each JVM (`java`) option which can be configured:

`-Xmx`::
The maximum heap size. For more inforamtion, see xref:setting_xmx[`Setting -Xmx`].

`-Xms`::
The initial heap size.
Setting the same value for initial and maximum (`-Xmx`) heap sizes avoids the JVM having to allocate memory after startup,
at the cost of possibly allocating more heap than is really needed. For Kafka and Zookeeper pods such allocation could
cause unwanted latency. For Kafka Connect avoiding over allocation may be the more important concern, especially in
distributed mode where the effects of over-allocation will be multiplied by the number of consumers.

NOTE: The units accepted by JVM settings such as `-Xmx` and `-Xms` are those accepted by the JDK `java`
binary in the corresponding image. Accordingly, `1g` or `1G` means 1,073,741,824 bytes, and `Gi` is not a valid unit
suffix. This is in contrast to the units used for xref:resources_json_config[memory limits and requests], which follow the
{ProductPlatformName} convention where `1G` means 1,000,000,000 bytes, and `1Gi` means 1,073,741,824 bytes

.Example fragment of a `Kafka` resource configuring `jvmOptions`
[source,json]
----
apiVersion: {KafkaApiVersion}
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    jvmOptions:
      "-Xmx": "2g"
      "-Xms": "2g"
    # ...
----

In the above example, the JVM will use 2 GiB (=2,147,483,648 bytes) for its heap.
Its total memory usage will be approximately 8GiB.

`-server`::
Selects the server JVM. This option can be set to true or false. Optional.

`-XX`::
A JSON Object for configuring advanced runtime options of a JVM. Optional

The `-server` and `-XX` options are used to configure the `KAFKA_JVM_PERFORMANCE_OPTS` option of Apache Kafka.

.More sophisticated example fragment of a `Kafka` resource configuring `jvmOptions`
[source,json]
----
apiVersion: {KafkaApiVersion}
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    "-server": true,
    "-XX":
      "UseG1GC": true,
      "MaxGCPauseMillis": 20,
      "InitiatingHeapOccupancyPercent": 35,
      "ExplicitGCInvokesConcurrent": true,
      "UseParNewGC": false
----

The example configuration above will result in the following JVM options:

[source]
----
-server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:-UseParNewGC
----

When neither of the two options (`-server` and `-XX`) is specified, the default Apache Kafka configuration of `KAFKA_JVM_PERFORMANCE_OPTS` will be used.

[[setting_xmx]]
== Setting `-Xmx`

The default value used for `-Xmx` depends on whether there is a xref:resources_json_config[memory limit] for the container:

* If there is a memory limit, the JVM's maximum memory will be limited according to the kind of pod (Kafka, Zookeeper,
Topic Operator) to an appropriate value less than the limit.
* Otherwise, when there is no memory limit, the JVM's maximum memory will be set according to the kind of pod and the
RAM available to the container.

[IMPORTANT]
====
Setting `-Xmx` explicitly is requires some care:

* The JVM's overall memory usage will be approximately 4 × the maximum heap, as configured by `-Xmx`.

* If `-Xmx` is set without also setting an appropriate {ProductPlatformName}
memory limit, it is possible that the container will be killed should the {ProductPlatformName} node
experience memory pressure (from other Pods running on it).

* If `-Xmx` is set without also setting an appropriate {ProductPlatformName}
memory request, it is possible that the container will scheduled to a node with insufficient memory.
In this case the container will start but crash (immediately if `-Xms` is set to `-Xmx`, or some later time if not).

====

When setting `-Xmx` explicitly, it is recommended to:

* set the memory request and the memory limit to the same value,
* use a memory request that is at least 4.5 × the `-Xmx`,
* consider setting `-Xms` to the same value as `-Xms`.

Furthermore, containers doing lots of disk I/O (such as Kafka broker containers) will need to leave some memory available
for use as operating system page cache. On such containers, the request memory should be substantially more than the
memory used by the JVM.

[[kafka_rack]]
== Kafka rack

It is possible to enable Kafka rack-awareness (more information can be found on the {KafkaRacks})
by specifying the `rack` object in the `spec.kafka` object of the `Kafka` resource.
The `rack` object has one mandatory field named `topologyKey`.
This key needs to match one of the labels assigned to the {ProductPlatformName} cluster nodes.
The label is used by {ProductPlatformName} when scheduling Kafka broker pods to nodes.
If the {ProductPlatformName} cluster is running on a cloud provider platform, that label should represent the availability zone where the node is running.
Usually, the nodes are labeled with `failure-domain.beta.kubernetes.io/zone` that can be easily used as `topologyKey` value.
This will have the effect of spreading the broker pods across zones, and also setting the brokers `broker.rack` configuration parameter.

.Example fragment of a `Kafka` resource configuring the `rack`
[source,json]
----
apiVersion: {KafkaApiVersion}
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    rack:
      topologyKey: failure-domain.beta.kubernetes.io/zone
    # ...
----

In the above example, the `failure-domain.beta.kubernetes.io/zone` node label will be used for scheduling Kafka broker Pods.

[[affinity]]
== Node and Pod Affinity

Node and Pod Affinity provide a flexible mechanism to guide the scheduling of pods to nodes by {ProductPlatformName}.
Node affinity can be used so that broker pods are preferentially scheduled to nodes with fast disks, for example.
Similarly, pod affinity could be used to try to schedule Kafka clients on the same nodes as Kafka brokers.
More information can be found on the {K8sAffinity}.

The format of the corresponding key is the same as the content supported in the Pod `affinity` in {ProductPlatformName}, that is: `nodeAffinity`, `podAffinity` and `podAntiAffinity`.

.Example fragment of a `Kafka` resource configured with `nodeAffinity`
[source,yaml]
----
apiVersion: {KafkaApiVersion}
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    # ...
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: kubernetes.io/e2e-az-name
              operator: In
              values:
              - e2e-az1
              - e2e-az2
    # ...
----

NOTE: When using both `affinity` and xref:kafka_rack[`rack`] be aware that `rack` uses a pod anti-affinity.
This is necessary so that broker pods are scheduled in different failure domains, as specified via the `topologyKey`.
This anti-affinity will not be present in the `Kafka` resource's `affinity`, but is still present on the StatefulSet and thus will still be considered by the scheduler.

[[topic_operator_json_config]]
== Topic Operator

Alongside the Kafka cluster and the Zookeeper ensemble, the Cluster Operator can also deploy the topic operator.
In order to do that, a `spec.topicOperator` object has to be included in the `Kafka` resource.
This object contains the topic operator configuration.
Without this object, the Cluster Operator does not deploy the topic operator.
It is still possible to deploy the topic operator by creating appropriate {ProductPlatformName} resources.

The YAML representation of the 'topicOperator` has no mandatory fields and if the value is an empty object
(just "{ }"), the Cluster Operator will deploy the topic operator with a default configuration.

The configurable fields are the following :

`image`::
The Docker image to be used by the Topic Operator.
The default value is determined by the value specified in the xref:STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE[`STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE`] environment variable of the Cluster Operator.
`watchedNamespace`::
The {ProductPlatformName} namespace in which the topic operator watches for topic ConfigMaps. Default is the namespace
where the topic operator is running.
`reconciliationIntervalMs`::
The interval between periodic reconciliations in milliseconds. Default is 900000 (15 minutes).
`zookeeperSessionTimeoutMs`::
The Zookeeper session timeout in milliseconds. Default is 20000 milliseconds (20 seconds).
`topicMetadataMaxAttempts`::
The number of attempts for getting topics metadata from Kafka. The time between each attempt is defined as an exponential
back-off. You might want to increase this value when topic creation could take more time due to its larger size (i.e.
many partitions / replicas). Default is `6`.
`resources`::
An object configuring the resource limits and requests for the topic operator container. The accepted JSON format is
described in the xref:resources_json_config[Resource limits and requests] section.
`affinity`::
Node and Pod affinity for the Topic Operator, as described in the xref:affinity[Node and Pod Affinity].
The format of the corresponding key is the same as the content supported in the Pod `affinity` in {ProductPlatformName}.
`tlsSidecar.image`::
The Docker image to be used by the sidecar container which provides TLS support for Topic Operator.
The default value is determined by the value specified in the xref:STRIMZI_DEFAULT_TLS_SIDECAR_TOPIC_OPERATOR_IMAGE[STRIMZI_DEFAULT_TLS_SIDECAR_TOPIC_OPERATOR_IMAGE`] environment variable of the Cluster Operator.
`tlsSidecar.resources`::
An object configuring the resource limits and requests for the sidecar container which provides TLS support for the Topic Operator.
For information about the accepted JSON format, see xref:resources_json_config[Resource limits and requests].

.Example Topic Operator JSON configuration
[source,json]
----
{ "reconciliationIntervalMs": "900000", "zookeeperSessionTimeoutMs": "20000" }
----

More information about these configuration parameters in the related xref:topic-operator-{context}[Topic Operator] documentation page.
