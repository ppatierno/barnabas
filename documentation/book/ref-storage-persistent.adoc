// Module included in the following assemblies:
//
// assembly-storage.adoc

[id='ref-persistent-storage-{context}']
= Persistent storage

Persistent storage uses {K8sPersistentVolumeClaims} to provision persistent volumes for storing data.
Persistent Volume Claims can be used to provision volumes of many different types, depending on the {K8SStorageClass} which will provision the volume.
The data types which can be used with persistent volume claims include many types of SAN storage as well as {K8sLocalPersistentVolumes}.

To use persistent storage, the `type` has to be set to `persistent-claim`.
Persistent storage supports additional configuration options:

`size` (required)::
Defines the size of the persistent volume claim, for example, "1000Gi".

`class` (optional)::
The {ProductPlatformName} {K8SStorageClass} to use for dynamic volume provisioning.

`subPath` (optional)::
The subPath on the persistent volume to use.  Default is to use the root directory of the associated
volume.

`selector` (optional)::
Allows selecting a specific persistent volume to use.
It contains key:value pairs representing labels for selecting such a volume.

`deleteClaim` (optional)::
Boolean value which specifies if the Persistent Volume Claim has to be deleted when the cluster is undeployed.
Default is `false`.

WARNING: Resizing persistent storage for existing {ProductName} clusters is not currently supported.
You must decide the necessary storage size before deploying the cluster.

.Example fragment of persistent storage configuration with 1000Gi `size`
[source,yaml]
----
# ...
storage:
  type: persistent-claim
  size: 1000Gi
# ...
----

The following example demonstrates the use of a storage class.

.Example fragment of persistent storage configuration with specific Storage Class
[source,yaml,subs="attributes+"]
----
# ...
storage:
  type: persistent-claim
  size: 1Gi
  class: my-storage-class
# ...
----

Finally, a `selector` can be used to select a specific labeled persistent volume to provide needed features such as an SSD.

.Example fragment of persistent storage configuration with selector
[source,yaml,subs="attributes+"]
----
# ...
storage:
  type: persistent-claim
  size: 1Gi
  selector:
    hdd-type: ssd
  deleteClaim: true
# ...
----

.Persistent Volume Claim naming

When the persistent storage is used, it will create Persistent Volume Claims with the following names:

`data-_cluster-name_-kafka-_idx_`::
Persistent Volume Claim for the volume used for storing data for the Kafka broker pod `_idx_`.

`data-_cluster-name_-zookeeper-_idx_`::
Persistent Volume Claim for the volume used for storing data for the Zookeeper node pod `_idx_`.

.SubPath Use Cases

A subPath is useful when multiple applications are sharing a Persistent Volume.  For example, a ZooKeeper
Cluster and a Kafka Cluster are using the same host and  link:https://kubernetes.io/docs/concepts/storage/volumes/#local[local persistent volume].
Each application will need to mount the volume with different subPath, which maps to different physical
storage directories.  (This configuration may not be performant, depending upon the disk's
link:https://en.wikipedia.org/wiki/IOPS[IOPs].  See link:https://kafka.apache.org/documentation/#diskandfs[Disks and Filesystem],
link:https://docs.confluent.io/current/kafka/deployment.html#disks[Running Kafka in Production],
link:https://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_designing[Single Machine Requirements], and
link:https://docs.confluent.io/current/zookeeper/deployment.html#disks[Running ZooKeeper in Production] for more details.)

Even when the application has sole use of the physical volume, a subPath may be needed.  On ext4
volumes, the 'lost+found' recovery directory in the root of the volume will be interpreted by Kafka
as a corrupt topic, causing startup to fail with a ```'lost+found' is not in the form of topic-partition```
KafkaException.