== Security

The Apache Kafka project supports data encryption by means of SSL/TLS protocol.
It's possible to encrypt data transferred between brokers and clients and between brokers (intra cluster communication).
Leveraging the SSL/TLS support, it's also possible to have mutual authentication with the connected client providing its own certificate for being authenticated by the Kafka cluster.
The Cluster Operator is in charge to setting up the SSL/TLS infrastructure by means of certificates for providing the security.

=== Certificates

Each Kafka broker needs its own private and public keys in order to support encryption.
The public key has to be signed in order to have a related X.509 certificate for providing server authentication and encrypting the communication channel with the client (which could be another broker as well).
More precisely, each broker has two different certificates (and related private keys) for intra cluster communication (with other brokers, i.e. during transferring messages from leader to follower partitions) and for communication with clients.
For signing broker certificates, two different private CA (Certification Autorithy) self-signed certificates are used : the first one named "internal-ca" is used across different deployed Kafka clusters for signing broker certificates used in the intra cluster communication; the second one is named "clients-ca" which is cluster specific (one CA for each cluster) and it's used for signing broker certificates used for communicating with clients.

All the generated certificates are saved as Secrets in the {ProductPlatformName} cluster.

* `internal-ca`: it contains the private and public keys, so the self-signed certificate, used for signing broker certificates used for intra cluster communication. It's common to all the Kafka clusters deployed by the Cluster Operator.
* `<cluster-name>-kafka-clients-ca`: it contains the private and public keys, so the self-signed certificate, used for signing broker certificates used for communicating with clients. It's specific for each deployed Kafka cluster as specified in the <cluster-name> prefix.
* `<cluster-name>-kafka-cert`: it contains only the public keys, so the self-signed certificate, used for signing broker certificates used for communicating with clients. This Secret should be used by the final Kafka cluster user in order to extract this certificate to put into the trusted store of his clients for verifying broker identities (server authentication).
* `<cluster-name>-kafka-brokers-internal`: it contains all the brokers private and public keys (certificates signed with "internal-ca") used for intra cluster communication.
* `<cluster-name>-kafka-brokers-clients`: it contains all the brokers private and public keys (certificates signed with specific cluster "clients-ca") used for communicating with clients.

All the keys are generate with 2048 bits as size and all the certificates have an expiration of 365 days.

=== Listeners

The data encryption is provided on two different listeners exposed by each Kafka broker.

The intra cluster communication is through the REPLICATION listener (on port 9091) which is encrypted by default.

The encrypted communication with clients is provided with the CLIENTTLS listener (on port 9093).

NOTE: Un-encrypted communication with clients is still possible through the CLIENT listener (on port 9092).

=== Clients connection via TLS

If the Kafka client wants to connect to the encrypted listener (CLIENTTLS) on port 9093, it needs the clients CA certificate in order to validate the broker certificate received during the SSL/TLS handshake (server authentication).
The clients CA certificate can be extracted from the generated `<cluster-name>-kafka-cert` Secret with the following command if the Kafka cluster is running on {OpenShiftName}.

[source,shell]
oc get secret <cluster-name>-kafka-cert -o jsonpath='{.data.clients-ca\.crt}' | base64 -d > clients-ca.crt

ifdef::Kubernetes[]
If the Kafka cluster is running on {KubernetesName}, the same result can be achieved with the following command.

[source,shell]
kubectl get secret <cluster-name>-kafka-cert -o jsonpath='{.data.clients-ca\.crt}' | base64 -d > clients-ca.crt

endif::Kubernetes[]
The native Kafka client, in order to use it, needs the certificate to be imported in a trust store using the `keytool` command line tool.

[source,shell]
keytool -keystore client.truststore.jks -alias CARoot -import -file clients-ca.crt

Finally, the minimal content for the properties file used by the Kafka client is the following (the password can be omitted if not needed).

[source]
security.protocol=SSL
ssl.truststore.location=/var/private/ssl/client.truststore.jks
ssl.truststore.password=test1234