// Module included in the following assemblies:
//
// assembly-using-the-kafka-bridge.adoc

[id='con-requests-kafka-bridge-{context}']
= Requests to the {ProductName} Kafka Bridge

== Authentication and encryption

Authentication and encryption between external clients and the Kafka Bridge is not yet supported. This means that requests sent from external clients to the Kafka Bridge are:

* Not encrypted, and must use HTTP rather than HTTPS

* Sent without authentication

Within your {ProductPlatformName} cluster, you can configure TLS or SASL-based authentication between the Kafka Bridge and your Kafka cluster. For more information, see LINK TO CHAPTER 3 **Connecting to Kafka brokers with Authentication**. 

== Data formats and headers

Use the following information to help you submit valid requests to the Kafka Bridge. 

=== Content Type headers

API request and response bodies are always encoded as JSON. 

* When performing consumer operations, `POST` requests must provide the following `Content-Type` header:
+
[source,http,subs=+quotes]
----
Content-Type: application/vnd.kafka.v2+json
----

* When performing producer operations, `POST` requests must provide the following `Content-Type` header specifying the *embedded data format* of the consumer, either `json` or `binary`:
+ 
[source,http,subs=+quotes]
----
Content-Type: application/vnd.kafka._embedded-data-format_.v2+json
----

For more information on the embedded data format, see the next section.

=== Embedded data format

When creating a consumer by making a `POST` request to the `/consumers/{groupid}` endpoint, you must specify a data format of either JSON or binary. This is specified in the `format` field of the request body, for example:

[source,json,subs=attributes+]
----
{
  "name": "my-consumer",
  "format": "binary",
...
}
----

This is referred to as the **embedded data format**. The embedded data format of a consumer must match the data format of the Kafka messages to be consumed. 

For an embedded data format of `binary`, subsequent producer requests must provide the binary data as Base64-encoded strings. For example, when sending messages by making `POST` requests to the `/topics/{topicname}` endpoint, the `POST` request body must specify the `value` of a binary message as shown:

[source,json,subs=attributes+]
----
{
  "records": [
    {
      "key": "my-key",
      "value": "ZWR3YXJkdGhldGhyZWVsZWdnZWRjYXQ="
    },    
  ]
}
----

Producer requests must provide a `Content-Type` header (for example, `Content-Type: application/vnd.kafka.binary.v2+json`) that corresponds to the embedded data format of the consumer that will consume the messages. 

=== Accept headers

After creating a consumer, all subsequent requests must provide an `Accept` header in the following format:

[source,http,subs=+quotes]
----
Accept: application/vnd.kafka._embedded-data-format_.v2+json
----

Where the `embedded-data-format` is the embedded data format of the consumer: either `json` or `binary`. The `+json` query parameter is not changed. 

For example, when committing a list of consumer offsets for a consumer that has an embedded data format of JSON, include this Accept header:

[source,http,subs=+quotes]
----
Accept: application/vnd.kafka.json.v2+json
----

== API version

Using v2.

application/vnd.kafka.[embedded_format].[api_version]+[serialization_format]


== HTTP Verbs

The quick brown fox.