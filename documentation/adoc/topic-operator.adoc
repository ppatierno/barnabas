== Topic Operator

The Topic Operator is in charge of managing topics in a Kafka cluster. The Topic Operator is deployed as a process
running inside a Kubernetes/OpenShift cluster.
It can be deployed through the Cluster Operator or "manually" through provided YAML files.

image::topic_operator.png[Topic Operator]

The role of the topic operator is to keep a set of Kubernetes ConfigMaps describing Kafka topics in-sync with
corresponding Kafka topics.

Specifically:
 
* if a config map is created, the operator will create the topic it describes
* if a config map is deleted, the operator will delete the topic it describes
* if a config map is changed, the operator will update the topic it describes

And also, in the other direction:

* if a topic is created, the operator will create a config map describing it
* if a topic is deleted, the operator will create the config map describing it
* if a topic is changed, the operator will update the config map describing it

This is beneficial to a Kubernetes/OpenShift-centric style of deploying 
applications, because it allows you to declare a ConfigMap as part of your
applications deployment and the operator will take care of creating
the topic for you, so your application just needs to deal with producing 
and/or consuming from the necessary topics.

Should the topic be reconfigured, reassigned to different Kafka nodes etc, 
the ConfigMap will always be up to date.


=== Reconciliation

A fundamental problem that the operator has to solve is that there is no
single source of truth: 
Both the ConfigMap and the topic can be modified independently of the operator.
Complicating this, the topic operator might not always be able to observe
changes at each end in real time (the operator might be down etc).
 
To resolve this, the operator maintains its own private copy of the
information about each topic. 
When a change happens either in the Kafka cluster, or 
in Kubernetes/OpenShift, it looks at both the state of the other system, and at its 
private copy in order to determine what needs to change to keep everything in sync.  
The same thing happens whenever the operator starts, and periodically while its running.

For example, suppose the topic operator is not running, and a ConfigMap "my-topic" gets created.
When the operator starts it will lack a private copy of "my-topic",
so it can infer that the ConfigMap has been created since it was last running. 
The operator will create the topic corresponding to "my-topic" and also store a private copy of the
metadata for "my-topic".

The private copy allows the operator to cope with scenarios where the topic
config gets changed both in Kafka and in Kubernetes/OpenShift, so long as the 
changes are not incompatible (e.g. both changing the same topic config key, but to 
different values). 
In the case of incompatible changes, the Kafka configuration wins, and the ConfigMap will 
be updated to reflect that. Defaulting to the Kafka configuration ensures that, 
in the worst case, data won't be lost. 

The private copy is held in the same ZooKeeper ensemble used by Kafka itself. 
This mitigates availability concerns, because if ZooKeeper is not running
then Kafka itself cannot run, so the operator will be no less available
than it would even if it was stateless. 


=== Usage Recommendations

. Try to either always operate on ConfigMaps or always operate directly on topics.
. When creating a ConfigMap:
    * Remember that you can't easily change the name later.
    * Choose a name for the ConfigMap that reflects the name of the topic it describes.
    * Ideally the ConfigMap's `metadata.name` should be the same as its `data.name`.
      To do this, the topic name will have to be a https://github.com/kubernetes/community/blob/master/contributors/design-proposals/architecture/identifiers.md[valid Kubernetes resource name].
. When creating a topic:
    * Remember that you can't change the name later.
    * It's best to use a name that is a https://github.com/kubernetes/community/blob/master/contributors/design-proposals/architecture/identifiers.md[valid Kubernetes resource name],
      otherwise the operator will have to sanitize the name when creating
      the corresponding ConfigMap.

[[topic_config_map_details]]
=== Format of the ConfigMap

By default, the operator only considers ConfigMaps having the label `strimzi.io/kind=topic`,
but this is configurable via the `STRIMZI_CONFIGMAP_LABELS` environment variable.

The `data` of such ConfigMaps supports the following keys:

* `name` The name of the topic. Optional; if this is absent the name of the ConfigMap itself is used.
* `partitions` The number of partitions of the Kafka topic. This can be increased, but not decreased. Required. 
* `replicas` The number of replicas of the Kafka topic. This cannot be larger than the number of nodes in the Kafka cluster. Required.
* `config` A string in JSON format representing the https://kafka.apache.org/documentation/#topicconfigs[topic configuration]. Optional, defaulting to the empty set.
 

=== Example

Suppose you want to create a topic called "orders" with 10 partitions and 2 replicas. 

You would first prepare a ConfigMap:

.Topic declaration ConfigMap
[source,yaml]
----
apiVersion: v1
kind: ConfigMap
metadata:
  name: orders
  labels:
    strimzi.io/kind: topic
    strimzi.io/cluster: my-cluster
data:
  name: orders
  partitions: "10"
  replicas: "2"
----

NOTE: When the Topic Operator is deployed manually the `strimzi.io/cluster` label is not necessary.

Because the `config` key is omitted from the `data` the topic's config will be empty, and thus default to the 
Kafka broker default.

You would then create this ConfigMap in Kubernetes:

[source]
----
kubectl create -f orders-topic.yaml
----
    
Or in OpenShift:

[source]
----
oc create -f orders-topic.yaml
----

That's it! The operator will create the topic "orders".

Suppose you later want to change the log segment retention time to 4 days, 
you can update `orders-topic.yaml` like this:

.Topic declaration ConfigMap with "config" update
[source,yaml]
----
apiVersion: v1
kind: ConfigMap
metadata:
  name: orders
  labels:
    strimzi.io/kind: topic
    strimzi.io/cluster: my-cluster
data:
  name: orders
  partitions: "10"
  replicas: "2"
  config: '{ "retention.ms":"345600000" }'
----

And use `oc update -f` or `kubectl update -f` to up update the ConfigMap 
in OpenShift/Kubernetes.


=== Unsupported operations

* You can't change the `data.name` key in a ConfigMap, because Kafka doesn't support changing topic names.
* You can't decrease the `data.partitions`, because Kafka doesn't support this.
* You should exercise caution in increasing `data.partitions` for topics with keys, as it will change 
  how records are partitioned. 

    
=== Operator environment

The operator is configured from environment variables:

* `STRIMZI_CONFIGMAP_LABELS` 
– The Kubernetes label selector used to identify ConfigMaps to be managed by the operator.
  Default: `strimzi.io/kind=topic`.
* `STRIMZI_ZOOKEEPER_SESSION_TIMEOUT_MS`
– The Zookeeper session timeout, in milliseconds. For example `10000`. Default: `20000` (20 seconds).
* `STRIMZI_KAFKA_BOOTSTRAP_SERVERS`
– The list of Kafka bootstrap servers. This variable is mandatory.
* `STRIMZI_ZOOKEEPER_CONNECT`
– The Zookeeper connection information. This variable is mandatory.
* `STRIMZI_FULL_RECONCILIATION_INTERVAL_MS`
– The interval between periodic reconciliations, in milliseconds.
* `STRIMZI_TOPIC_METADATA_MAX_ATTEMPTS`
– The number of attempts for getting topics metadata from Kafka. The time between each attempt is defined as an exponential
back-off. You might want to increase this value when topic creation could take more time due to its larger size
(i.e. many partitions/replicas). Default `6`.

If the operator configuration needs to be changed the process must be killed and restarted.
Since the operator is intended to execute within Kubernetes, this can be achieved
by deleting the pod.


=== Resource limits and requests

The Topic Operator can run with resource limits:

* When it is deployed by the Cluster Operator these can be specified in the `resources` key of the `topic-operator-config`.
* When it is not deployed by the Cluster Operator these can be specified on the Deployment in the usual way.

==== Minimum Resource Requirements

Testing has shown that the topic operator functions adequately with 96Mi of memory and 100m CPU when watching two topics.
It is therefore recommended to use these as a minimum when configuring resource requests and not to run it with lower limits than these. If the Kafka cluster has more than a handful of topics more generous requests and limits will be necessary.
