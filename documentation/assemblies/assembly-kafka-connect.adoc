// This assembly is included in the following assemblies:
//
// assembly-getting-started.adoc

// Save the context of the assembly that is including this one.
// This is necessary for including assemblies in assemblies.
// See also the complementary step on the last line of this file.

[id='kafka-connect-{context}']
= Kafka Connect

link:https://kafka.apache.org/documentation/#connect[Kafka Connect^] is a tool for streaming data between Apache Kafka and external systems. It provides a framework for moving large amounts of data into and out of your Kafka cluster while maintaining scalability and reliability. Kafka Connect is typically used to integrate Kafka with external databases and storage and messaging systems.

In Kafka Connect, a _source connector_ is a runtime entity that fetches data from an external system and feeds it to Kafka as messages. A _sink connector_ is a runtime entity that fetches messages from Kafka topics and feeds them to an external system. The workload of connectors is divided into _tasks_. Tasks are distributed among nodes (also called _workers_), which form a _Connect cluster_. This allows the message flow to be highly scalable and reliable.

Each connector is an instance of a particular _connector class_ that knows how to communicate with the relevant external system in terms of messages. Connectors are available for many external systems, or you can develop your own.

The term _connector_ is used interchangably to mean a connector instance running within a Kafka Connect cluster, or a connector class. This guide uses the term _connector_ when the meaning is clear from the context.

{ProductName} allows you to:

* Create a Kafka Connect image containing the connectors you want

* Deploy and manage a Kafka Connect cluster running within Kubernetes using a `KafkaConnect` resource

* Run connectors within your Kafka Connect cluster, optionally managed using `KafkaConnector` resources

Kafka Connect includes the following built-in connectors for moving file-based data into and out of your Kafka cluster.

[cols="2*",options="header",stripes="none",separator=¦]
|===

¦File Connector
¦Description

m¦FileStreamSourceConnector
¦Transfers data to your Kafka cluster from a file (the source).

m¦FileStreamSinkConnector
¦Transfers data from your Kafka cluster to a file (the sink).

|===

To use other connector classes, you need to prepare connector images by following one of these procedures:

* xref:creating-new-image-from-base-{context}[] 

* xref:using-openshift-s2i-create-image-str[] (OpenShift only)

The Cluster Operator can use images that you create to deploy a Kafka Connect cluster to your Kubernetes cluster.

A Kafka Connect cluster is implemented as a `Deployment` with a configurable number of workers.

You can xref:con-creating-managing-connectors-{context}[create and manage connectors] using `KafkaConnector` resources or manually using the Kafka Connect REST API, which is available on port 8083 as the `<connect-cluster-name>-connect-api` service. The operations supported by the REST API are described in the link:https://kafka.apache.org/documentation/#connect_rest[Apache Kafka documentation^].

include::../modules/proc-deploying-kafka-connect.adoc[leveloffset=+1]

include::assembly-using-kafka-connect-with-plugins.adoc[leveloffset=+1]

include::../modules/con-creating-managing-connectors.adoc[leveloffset=+1]

include::../modules/kafkaconnectors/proc-deploying-kafkaconnector.adoc[leveloffset=+1]